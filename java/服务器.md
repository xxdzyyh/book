



# 服务器

[TOC]



### Tomcat

Tomcat是常见的免费的web服务器.

Tomcat是一个世界上广泛使用的支持 jsp 和servlets的Web服务器

1. 不使用 Tomcat 也可以访问html，直接通过文件路径访问
   `file:///Users/mac/Desktop/1.0.html`

2. 使用 Tomcat，我们可以使用 http://127.0.0.1:8080/1.0.html 进行访问



### JSP

**JSP**（全称Java Server Pages）是由Sun Microsystems公司主导创建的一种动态网页技术标准。JSP部署于网络服务器上，可以响应客户端发送的请求，并根据请求内容动态地生成HTML、XML网页，然后返回给请求者。JSP技术以Java语言作为脚本语言，为用户的HTTP请求提供服务，并能与服务器上的其它Java程序共同处理复杂的业务需求。

JSP将Java代码和特定变动内容嵌入到静态的页面中，实现以静态页面为模板，动态生成其中的部分内容。JSP引入了被称为“JSP动作”的XML标签，用来调用内建功能。另外，可以创建JSP标签库，然后像使用标准HTML或XML标签一样使用它们。标签库能增强功能和服务器性能，而且不受跨平台问题的限制。JSP文件在运行时会被其编译器转换成更原始的Servlet代码。JSP编译器可以把JSP文件编译成用Java代码写的Servlet，然后再由Java编译器来编译成能快速执行的二进制机器码，也可以直接编译成二进制码。

Java Servlet技术简称**Servlet**技术， 是Java开发Web应用的底层技术。

但由于Servlet用起来太复杂了，SUN公司发布了JavaServerPages（**JSP**）技术，以进一步简化servlet程序开发。

自从Servlet和JSP技术诞生后，涌现出大量的基于Java的Web框架来帮助开发人员快速编写Web应用。这些框架构建于Servlet和JSP之上，帮助开发人员更加关注业务逻辑，无须编写重复性（技术）代码。而**Spring MVC** 就是当前最流行的可扩展Java Web应用开发框架。

Spring MVC又叫Spring Web MVC，是Spring框架的一个模块，用于快速开发Web应用。 MVC代表Model-View-Controller，是一个广泛应用于GUI开发的设计模式。



### JPA

JPA是Java Persistence API的简称，中文名Java持久层API，是JDK 5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体[对象持久化](https://baike.baidu.com/item/对象持久化/7316192)到数据库中。

> ORM : 对象关系映射



#### Servlet

Servlet是一个Java程序，一个Servlet应用有一个或多个Servlet程序。Servlet也是Java的一个接口，我们在编写servlet时要实现这个接口，按照其规范进行操作。JSP页面会被转换和编译成Servlet程序。

我们在学习的时候会知道，写好的JSP代码要部署到Tomcat上才能被访问并运行。

### Servlet 和 Tomcat

Servlet应用无法独立运行，必须运行在Servlet容器中。**Tomcat** 是Web应用服务器，就是一个Servlet/JSP容器。Servlet容器将用户的请求传递给Servlet应用，并将结果返回给用户。Web服务器和Web客户端间通过HTTP协议通信，因此Web服务器也叫HTTP服务器。

#### Spring 和 SpringMVC

**Spring**框架是一个开源的企业应用开发框架，有很多不同的模块，**Spring MVC**就是其中一个模块。

Java Web应用开发中有两种设计模型：

第一次学习JSP，通常通过链接方式进行JSP页面间的跳转，这就是**第一种模式**。这种方式非常直接，但在中型和大型应用中，这种方式会带来维护上的问题。修改一个JSP页面的名字，会导致大量页面中的链接需要修正。

**第二种模式**就是基于模型-视图-控制器的模式（MVC模式），一个实现MVC模式的应用包含模型、视图和控制器3个模块。视图负责应用的展示。模型封装了应用的数据和业务逻辑。Spring MVC 使用一个Servlet作为控制器，大部分都采用JSP页面作为应用的视图，而模型则采用POJO，实践中会采用一个JavaBean来持有模型状态。



#### Spring Bean

Spring Bean是被实例的，组装的及被Spring 容器管理的Java对象。

Spring 容器会自动完成@bean对象的实例化。

创建应用对象之间的协作关系的行为称为：**装配(wiring)**，这就是依赖注入的本质。

### Spring 三种配置方案

1.在XML中进行显示配置
2.使用Java代码进行显示配置
3.隐式的bean发现机制和自动装配
**推荐方式：** 3>2>1



组件扫描默认是不开启用的，我们还需要显示配置下Spring,从而命令它去寻找带有@Component注解的类，并为其创建bean。

xml启动组件扫描

```
<?xml version="1.0" encoding="utf-8" ?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:context="http://www.springframework.org/schema/context"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context.xsd">
    <context:component-scan base-package="com.stalkers.impl"/>
</beans>
```



**@Component**：表明该类会作为组件类。

Spring应用上下文种所有的bean都会给定一个ID。在前面的例子中，尽管我们没有明确地为JayDisc bean设置ID,但是Spring会默认为JayDisc设置ID为jayDisc，**也就是将类名的第一个字母变成小写**。

如果想为这个bean设置不同的ID,那就将期望的值传递给@Component注解

```
@Component("zhoujielun")
public class JayDisc implements ICompactDisc {

}
```

如果所有的对象都是独立的，彼此之间没有任何依赖，那么使用组件扫描就能自动化装配bean。

但是实际工作中，很多对象会依赖其他对象完成任务。这时候就需要能够**将组件扫描得到的bean**和他们依赖装配在一起。这就是**自动装配（autowiring）**

#### @Autowired

@Autowired 与@Resource的区别： 

1. @Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。

2. @Autowired默认按类型装配（这个注解是属业spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下：

```
@Autowired() @Qualifier("baseDao") 
private BaseDao baseDao;
```

3. @Resource（这个注解属于J2EE的），默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。

```
@Resource (name="baseDao") private BaseDao baseDao;
```

推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。

CDPlayer类的构造器上添加了@Autowired注解，表明当Spring创建CDPlayerbean的时候，会通过这个构造器来进行**实例化**

```
@Component
public class CDPlayer implements IMediaPlayer {
 
    private ICompactDisc cd;
    
    @Autowired
    public CDPlayer(ICompactDisc cd) {
        this.cd = cd;
    }
 
    public void play() {
        System.out.println("cd Play:");
        cd.play();
    }
}
```

**Autowired的多种方式**
1.构造器注解(constructor)

2.属性setter注解

3.field注解

不管使用上面3中的哪个方法，Spring都会满足声明的依赖。假如**有且只有一个bean**匹配依赖的话，那么这个bean将会被装配进来。

如果使用2，3方式注解，有多个bean的话，则用**Qualifier**指定。

如果没有匹配的bean，那么在应用上下文创建的时候，Spring会抛出一个异常。为了避免异常的出现，可以使用

```
@Autowired(required = false)
private IMediaPlayer CDPlayer;
```



尽管在很多场景下通过组件扫描和自动装配实现Spring的自动化更为推荐，但是有时候行不通。比如引用第三方组件，没办法在它的类上添加@Component及@Autowired。所以就需要**JavaConfig**或者**XML配置**



在进行显示配置的时候，JavaConfig是更好的解决方案。

JavaConfig与其他的Java代码又有所区别，在概念上它与应用程序中的业务逻辑和领域代码又有所不同。JavaConfig是配置相关代码，不含任何逻辑代码。**通常会将JavaConfig放到单独的包中。**

创建JavaConfig类

```
@Configuration
public class CDPlayerConfig {
}
```

使用@Configuration表明CDPlayerConfig是一个配置类

声明简单的bean

```
@Bean
public IMediaPlayer cdplayer() {
    return new VCDPlayer(new JayCompactDisc());
}
```

@Bean注解会告诉Spring将返回一个对象。



单独抽出disc()方法，在其方法上加上Bean注解，Spring上加@Bean注解的都是**默认单例模式**，不管disc()被多个方法调用，其disc()都是同一个实例。



```
@Bean
public IMediaPlayer cdplayer() {
    return new VCDPlayer(disc());
}

@Bean
public ICompactDisc disc() {
    return new JayCompactDisc();
}
```



#### loC

**控制反转**（Inversion of Control，缩写为**IoC**），是[面向对象编程](https://baike.baidu.com/item/面向对象编程/254878)中的一种设计原则，可以用来减低计算机[代码](https://baike.baidu.com/item/代码/86048)之间的[耦合度](https://baike.baidu.com/item/耦合度/2603938)。其中最常见的方式叫做**[依赖注入](https://baike.baidu.com/item/依赖注入/5177233)**（Dependency Injection，简称**DI**），还有一种方式叫“依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。

```
// 直接依赖
class Room {
	Light light = null;

	getLight() {
		if (ligth == null) {
			ligth = new Light()
		}
	}
}

// 依赖注入
class Room {
	Light light = null;

	Room(Ligth light) {
		this.light = light
	}
}

```



在Spring中，我们基本不需要 `new` 一个类，这些都是让 Spring 去做的。

Spring 启动时会把所需的类实例化成对象，如果需要依赖，则先实例化依赖，然后实例化当前类。

因为依赖必须通过构建函数传入，所以实例化时，当前类就会接收并保存所有依赖的对象。



在 Spring 中，**类的实例化、依赖的实例化、依赖的传入**都交由 Spring Bean 容器控制，

而不是用`new`方式实例化对象、通过非构造函数方法传入依赖等常规方式。

实质的控制权已经交由程序管理，而不是程序员管理，所以叫做控制反转。



**Bean容器**，或称spring ioc容器，主要用来管理对象和依赖，以及依赖的注入。

bean是一个**Java对象**，根据bean规范编写出来的类，并由bean容器生成的对象就是一个bean。

bean规范如下：

1. 所有属性为private

2. 提供默认构造方法

3. 提供getter和setter

4. 实现serializable接口



### @Configuration

@Configuration用于定义配置类，可替换xml配置文件，被注解的类内部包含有一个或多个被@Bean注解的方法，这些方法将会被AnnotationConfigApplicationContext或AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义，初始化Spring容器。

@Configuration定义的配置类需要指出如何构建bean，一般就是new。

```
@Bean
public CacheManager cacheManager() {
    return new BCacheManager();
}
```



@Configuration标注在类上，相当于把该类作为spring的xml配置文件中的`<beans>`，作用为：配置spring容器(应用上下文)

@Bean标注在方法上(返回某个实例的方法)，等价于spring的xml配置文件中的`<bean>`，作用为：注册bean对象



### 常见注解说明

| 注解名称                      | 注解作用                                                     |      |
| ----------------------------- | ------------------------------------------------------------ | ---- |
| @SpringBootApplication        | 申明让spring boot自动给程序进行必要的配置，这个配置等同于：@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 |      |
| @Configuration                | 等同于spring的XML配置文件；使用Java代码可以检查类型安全      |      |
| @EnableAutoConfiguration      | 自动配置，尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库” |      |
| @ComponentScan                | 组件扫描，可自动发现和装配一些Bean                           |      |
| @Component                    | 泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。可配合CommandLineRunner使用，在程序启动后执行一些基础任务。 |      |
| @PathVariable                 | 获取参数                                                     |      |
| @JsonBackReference            | 解决嵌套外链问题                                             |      |
| @RepositoryRestResourcepublic | 合spring-boot-starter-data-rest使用                          |      |
| @RestController               | @Controller和@ResponseBody的合集,表示这是个控制器bean,并且是将函数的返回值直 接填入HTTP响应体中,是REST风格的控制器。 |      |
| @ResponseBody                 | 表示该方法的返回结果直接写入HTTP response body中，一般在异步获取数据时使用，用于构建RESTful的api。在使用@RequestMapping后，返回值通常解析为跳转路径，加上@responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。 |      |
| @Controller                   | 用于定义控制器类，在spring 项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层），一般这个注解在类中，通常方法需要配合注解@RequestMapping。 |      |
| @RequestMapping               | 提供路由信息，负责URL到Controller中的具体函数的映射          |      |
| @ImportResource               | 用来加载xml配置文件                                          |      |
| @Service                      | 一般用于修饰service层的组件                                  |      |
| @Repository                   | 使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 |      |
| @Bean                         | 用@Bean标注方法等价于XML中配置的bea                          |      |
| @Value                   | 注入Spring boot application.properties配置的属性的值 |      |
| @Inject | 等价于默认的@Autowired，只是没有required属性 | |
| @Qualifier | 当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。 | |
| @Resource(name="name",type="type") | 没有括号内内容的话，默认byName。与@Autowired干类似的事。 | |
| @ControllerAdvice | 全局异常处理 全局数据绑定 全局数据预处理 | |

##### @ControllerAdvice

使用 @ControllerAdvice 实现全局异常处理，只需要定义类，添加该注解即可定义方式如下：

```java
@ControllerAdvice
public class MyGlobalExceptionHandler {
    @ExceptionHandler(Exception.class)
    public ModelAndView customException(Exception e) {
        ModelAndView mv = new ModelAndView();
        mv.addObject("message", e.getMessage());
        mv.setViewName("myerror");
        return mv;
    }
}
```

在该类中，可以定义多个方法，不同的方法处理不同的异常，例如专门处理空指针的方法、专门处理数组越界的方法...，也可以直接向上面代码一样，在一个方法中处理所有的异常信息。

@ExceptionHandler 注解用来指明异常的处理类型，即如果这里指定为 NullpointerException，则数组越界异常就不会进到这个方法中来。

### 查看所有的Bean

```
package com.sjtech.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
import org.springframework.context.ApplicationContext;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.CommandLineRunner;

import java.util.Arrays;

@SpringBootApplication
@EnableDiscoveryClient
@RestController
public class GatewayApplication extends SpringBootServletInitializer implements CommandLineRunner {
    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }

    @Autowired
    private ApplicationContext appContext;

    @Override
    public void run(String... args) throws Exception {
        String[] beans = appContext.getBeanDefinitionNames();
        Arrays.sort(beans);
        for (String bean : beans)
        {
            System.out.println(bean + " of Type :: " + appContext.getBean(bean).getClass());
        }
    }
}

```



使用 IDEA 开发的时候，选中正在运行的项目，EndPoints 可以查看当前的 Beans。

![截屏2020-12-26 上午11.20.02](/Users/mac/WorkSpace/LearnWebProject/截屏2020-12-26 上午11.20.02.png)





#### SpringBoot Starter

starter 可以简单的认为就是一个第三方。

只是说这个第三方将自己依赖的东西都捆绑到了一起，这样我们就不需要去配置这些第三方。

SpringBoot提供的starter以`spring-boot-starter-xxx`的方式命名的。

官方建议自定义的starter使用`xxx-spring-boot-starter`命名规则。以区分SpringBoot生态提供的starter。



其实非常类似于 iOS 工程的依赖，



SpringBoot 

bootstrap.yml（bootstrap.properties）用来在程序引导时执行，应用于更加早期配置信息读取，如可以使用来配置application.yml中使用到参数等

application.yml（application.properties) 应用程序特有配置信息，可以用来配置后续各个模块中需使用的公共参数等。

bootstrap.yml 先于 application.yml 加载



### Spring Cloud Gateway



<img src="/Users/mac/WorkSpace/LearnWebProject/20190703211815129.png" alt="20190703211815129" style="zoom:50%;" />



```
spring:
  application: auth-gateway
  servlet:
    multipart:
      max-file-size: 20MB
      max-request-size: 50MB
  cloud:
    zookeeper:
      discovery:
        enabled: true
      connect-string: localhost:2181
    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: "*"
            allowedHeaders: "*"
            allowCredentials: True
            allowedMethods:
              - GET
              - POST
              - PUT
              - DELETE
              - OPTIONS
      discovery:
        locator:
          enabled: true
          lower-case-service-id: true
      loadbalancer:
        use404: true
      routes:
        - id: dc-route
          uri: lb:http://data-collector  #see ReactiveLoadBalancerClientFilte(line:98)
          predicates:
            - Path=/dc/**
          filters:
            - AddIpRequestHeader=true #为请求添加ip头，将真实ip传递给服务
        - id: login-route
          uri: lb://gateway
          predicates:
            - Path=/api/login/**,/api/app/**,/api/combo/**,/api/logout/**
          filters:
            - StripPrefix=1
        - id: api-route
          uri: lb:http://web-api
          predicates:
            - Path=/api/**
          filters:
            - StripPrefix=1
```

####  配置解析

##### Cors （Cross-origin resource sharing）

CORS是一个W3C标准，全称是"跨域资源共享"（Cross-origin resource sharing）。



* Access-Control-Allow-Origin ： 可接受的域，是一个具体域名或者*，代表任意

- Access-Control-Allow-Credentials：是否允许携带cookie，默认情况下，cors不会携带cookie，除非这个值是true

**注意：**

如果跨域请求要想操作cookie，需要满足3个条件：

- 服务的响应头中需要携带Access-Control-Allow-Credentials并且为true。
- 浏览器发起ajax需要指定withCredentials 为true
- 响应头中的Access-Control-Allow-Origin一定不能为*，必须是指定的域名



```
discovery:
        locator:
          enabled: true
          lower-case-service-id: true
```

为服务发现中的服务生成路由,如果 zookeeper 中注册了两个服务 gateway, web-api，那就会生成两个路由 lb:web-api 和 lb:gateway。

路由的规则默认是lb:ServiceID大写，lower-case-service-id 改成小写。

> 路由配置

```
- id: dc-route
  uri: lb:http://data-collector  #see ReactiveLoadBalancerClientFilte(line:98)
  predicates:
    - Path=/dc/**
  filters:
    - AddIpRequestHeader=true 
```

其中filter 声明如下

```
@Component
public class AddIpRequestHeaderGatewayFilterFactory
        extends AbstractGatewayFilterFactory<AddIpRequestHeaderGatewayFilterFactory.Config> 
```

配置文件中默认省略 GatewayFilterFactory 。



### SpringBoot 单元测试

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-test</artifactId>
    <scope>test</scope>
</dependency>
```

Spring Boot中单元测试类写在在src/test/java目录下，你可以手动创建具体测试类，

如果是IDEA，则可以通过IDEA自动创建测试类，Navigate -> Test，也可以通过快捷键⇧⌘T(MAC)或Ctrl+Shift+T(Window)

```
package com.buginsight.springboot.controller;

import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.test.context.junit4.SpringRunner;

import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.zip.ZipOutputStream;

import static org.junit.Assert.*;

@RunWith(SpringRunner.class)
@SpringBootTest
public class ReportControllerTest {

    @Autowired
    private ReportController reportController;

    @org.junit.Before
    public void setUp() throws Exception {

    }

    @org.junit.After
    public void tearDown() throws Exception {

    }

    @org.junit.Test
    public void downloadReport() throws IOException {
        reportController.createZip();
    }
}
```

#### SpringBoot项目打包

工程目录下运行这个命令

```
mvn clean package
```

在项目的 target 文件夹下面忽悠

运行完后会生成 projectName.jar 文件,另外两个txt文件我们自己保存。这两个文件是mapping文件

```
projectName.jar
proguard_map.txt
proguard_seed.txt
```







### zookeeper

分布式调度器。



#### 启动

#### 连接 

```
zkCli -server 127.0.0.1:2181
```

#### 查看

```
$ ls /

[admin, brokers, cluster, config, consumers, controller, controller_epoch, dubbo, isr_change_notification, latest_producer_id_block, log_dir_event_notification, services, zookeeper]

$ ls /services

[gateway,web-api]
```



### Kafka


Kafka  是一种高吞吐量的分布式发布订阅消息系统，有如下特性：

通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。

高吞吐量  ：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。

支持通过Kafka服务器和消费机集群来分区消息。

支持 Hadoop 并行数据加载。 



* producer 

  消息生产者，像 kafka broker 发送消息的客户端

* consumer

  消息消费者，从  kafka broker 获取消息的客户端

* consumer group 

  消费者组，由多个 consumer 组成，组内消费者负责消费不同的分区，一个分区只能由一个消费者消费。消费者组是逻辑上的一个订阅者

* topic

   可以理解为一个队列，生产者和消费者面向的都是一个topic

* broker

  一台kafka服务器就是一个broker,一个集群由多个 broker 组成，一个broker 可以容纳多个 topic。

* partition

  topic 可以分布到多个broker上，一个topic可以分为多个partition,每个partition 是一个有序的队列

### 查看 kafka 启动结果

```
$ jps

2784 Jps
1892 Launcher
1109 QuorumPeerMain
2293 Kafka
1893 RemoteMavenServer36
389 
397

ps -ef | grep java
```



查看所有的topic

```
kafka-topics --zookeeper 127.0.0.1:2181 --list
```



### Maven

jar 第三方管理工具



### ClickHouse

列式存储数据库

#### Datagrip

数据库可视化工具

#### 查询

*sql*一般指结构化查询语言。结构化查询语言(Structured Query Language)简称*SQL*，是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统。

clickhouse 的查询语句也属于 SQL，和MySQL类似，大部分语句和MySQL是一致的，其实就是遵循了SQL规范。

```
SELECT
    sum(rows) AS `总行数`,
    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,
    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`
FROM system.parts
```



```
show databases
```

```
select * from session
where appIndex=18
AND userId IS NOT NULL
AND isFirstSession=1
AND startTime between toDateTime('2020-04-21 02:54:07') AND toDateTime('2020-12-21 02:54:07')
```



### Redis

Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。

Redis 与其他 key - value 缓存产品有以下三个特点：

- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。

- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。

- Redis支持数据的备份，即master-slave模式的数据备份。

  

#### Redis 优势

- 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。
- 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
- 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。
- 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。



#### Redis与其他key-value存储有什么不同？

- Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。
- Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。

### 使用

```
To have launchd start redis now and restart at login:
  brew services start redis
Or, if you don't want/need a background service you can just run:
  redis-server /usr/local/etc/redis.conf
```

* 安装

  ```
  brew install Redis   
  ```

* 后台启动

  ```
  brew services start redis
  ```

### Minio

Minio 是个基于 Golang 编写的开源对象存储套件。MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。

MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。

> 对象存储服务（Object Storage Service，OSS）是一种海量、安全、低成本、高可靠的云存储服务，适合存放任意类型的文件。
>
> 容量和处理能力弹性扩展，多种存储类型供选择，全面优化存储成本。



### 

@Service 用在服务提供者中，在类或者接口中声明。
服务提供者实现相关的服务接口，当消费端调用相关的类时，最终会调用提供者的实现方法。



### Dobbu

1. 服务容器Container 负责启动加载运行服务提供者Provider。根据Provider配置的文件根据协议发布服务 , 完成服务的初始化
2. Provider在启动时，根据配置中的Registry地址连接Registry，将Provider的服务信息发布到Registry，在Registry注册自己提供的服务
3. Consumer在启动时，根据消费者XML配置文件中的服务引用信息，连接到Registry，向Registry订阅自己所需的服务
4. Registry根据服务订阅关系，返回Provider地址列表给Consumer，如果有变更，Registry会推送最新的服务地址信息给Consumer
5. Consumer调用远程服务时，会根据路由策略，先从缓存的Provider地址列表中选择一台进行，跨进程调用服务，假如调用失败，再重新选另一台调用
6. 服务Provider和Consumer，会在内存中记录调用次数和调用时间，每分钟发送一次统计数据到Monitor



检查完配置文件和目录，仍然报这个错，只有去代码里找答案。在ConfigFileApplicationListener类中，可以看到 DEFAULT_SEARCH_LOCATIONS 默认加载位置有："classpath:/,classpath:/config/,file:./,file:./config/"，DEFAULT_NAMES 默认配置文件名："application"

![20190321194446511](LearnWebProject/20190321194446511.png)



```
#dubbo配置
dubbo.registry.address=zookeeper://127.0.0.1:2181
#dubbo.registry.address=zookeeper://10.13.64.107:2181,10.13.83.20:2181,10.13.103.51:2181

// 传输协议
dubbo.protocol.name=dubbo 
// 传输端口
dubbo.protocol.port=20880
```



###

```
org.apache.dubbo.rpc.RpcException: Failed to invoke the method getAllLogs in the service com.loginsight.interfaces.ILogService. Tried 3 times of the providers [192.168.28.69:20880] (1/1) from the registry 127.0.0.1:2181 on the consumer 192.168.28.69 using the dubbo version 2.7.4.1. Last error is: Invoke remote method timeout. method: getAllLogs, provider: dubbo://192.168.28.69:20880/com.loginsight.interfaces.ILogService?anyhost=true&application=web-api&bean.name=ServiceBean:com.loginsight.interfaces.ILogService:1.0.0&check=false&deprecated=false&dubbo=2.0.2&dynamic=true&generic=false&interface=com.loginsight.interfaces.ILogService&lazy=false&loadbalance=leastactive&methods=getAllLogs&pid=36231&qos.enable=false&register.ip=192.168.28.69&release=2.7.4.1&remote.application=accessor&revision=1.0.0&side=consumer&sticky=false&timeout=5000&timestamp=1625036872367&version=1.0.0, cause: org.apache.dubbo.remoting.TimeoutException: Waiting server-side response timeout by scan timer. start time: 2021-06-30 15:15:10.760, end time: 2021-06-30 15:15:15.772, client elapsed: 1 ms, server elapsed: 5011 ms, timeout: 5000 ms, request: Request [id=67, version=2.0.2, twoway=true, event=false, broken=false, data=RpcInvocation [methodName=getAllLogs, parameterTypes=[], arguments=[], attachments={path=com.loginsight.interfaces.ILogService, remote.application=web-api, interface=com.loginsight.interfaces.ILogService, version=1.0.0, timeout=5000}]], channel: /192.168.28.69:65080 -> /192.168.28.69:20880
```

getAllLogs 返回的是 List<LogDetailModel>,但是 LogDetailModel 没有实现 Serializable 接口，导致无法正确返回，dobbo 报错。



### shiro

https://zhuanlan.zhihu.com/p/54176956



#### 授权过程

1. 创建SecurityManager
2. 主体授权
3. SecurityManager授权
4. Authorizer授权
5. Realm获取角色权限数据

```
SimpleAccountRealm simpleAccountRealm = new SimpleAccountRealm();

// 账号 wmyskxz 密码 123456 Roles ["admin", "user"]
simpleAccountRealm.addAccount("wmyskxz", "123456", "admin", "user");

// 1.构建SecurityManager环境
DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager();
defaultSecurityManager.setRealm(simpleAccountRealm);

// 2.主体提交认证请求
SecurityUtils.setSecurityManager(defaultSecurityManager); // 设置SecurityManager环境
Subject subject = SecurityUtils.getSubject(); // 获取当前主体

UsernamePasswordToken token = new UsernamePasswordToken("wmyskxz", "123456");
subject.login(token); // 登录

// subject.isAuthenticated()方法返回一个boolean值,用于判断用户是否认证成功
System.out.println("isAuthenticated:" + subject.isAuthenticated()); // 输出true
// 判断subject是否具有admin和user两个角色权限,如没有则会报错
subject.checkRoles("admin","user");
// subject.checkRole("xxx"); // 报错
```



```
AuthCheckGatewayFilterFactory.java
private Mono<Void> doLogout(ServerWebExchange exchange) {
	
	getSubject(sessionId).logout();
}


// principals = null
// 导致没有执行下面的logout
// if (authc instanceof LogoutAware) {
      ((LogoutAware) authc).onLogout(principals);
   }
//
//
PrincipalCollection principals = subject.getPrincipals();
if (principals != null && !principals.isEmpty()) {
    if (log.isDebugEnabled()) {
        log.debug("Logging out subject with primary principal {}", principals.getPrimaryPrincipal());
    }
    Authenticator authc = getAuthenticator();
    if (authc instanceof LogoutAware) {
        ((LogoutAware) authc).onLogout(principals);
    }
}
```







### Mongo

常用命令

* show dbs

  显示数据库

* use db_name

  使用数据库

* show tables / show collections 

  显示所有的集合



字符串 用正则匹配长度大于0的字符串

```
{firstUserId : {$regex:/.+/}}
```

日期匹配

```
{firstUserId : {$regex:/.+/},firstSessionTime:{$gte:ISODate("2020-06-15T04:04:31.701Z")}}

{firstUserId : {$regex:/.+/},firstSessionTime:{$gte:ISODate("2020-06-15T04:04:31.701Z"),$lte:ISODate("2020-07-15T04:04:31.701Z")}}
```

```
db.account.update({'userName':'wangfeng','groupId':'wangxuefeng1608263725170'},{$set:{'accountType':'1'}})

db.account.update({'groupId':'wangxuefeng1608263725170','userName':'wang02'},{$set:{'licText':'AhHAqhZhWmDa6wQ/BcRM1TTLkzooojAB51GgxZ74Vl861y30cfGVYBTFXbvxr/YJO8uTU62W7fR8teQ0xLlLhTEFKpxM7BbhpEYjrlJRjhvr4NW6GAyurR8XXXtn5Gbq4EDnP+Jt/DTsSNCiGZEhyVSORfJYTc+e6/gXl9hVfb8='}})

db.account.find({'groupId':'wangxuefeng1608263725170','licText':''})
```

#### aggregate

MongoDB 中聚合(aggregate)主要用于处理数据(诸如统计平均值，求和等)，并返回计算后的数据结果。

有点类似 **SQL** 语句中的 **count(\*)**。

| 表达式    | 描述                                           | 实例                                                         |
| :-------- | :--------------------------------------------- | :----------------------------------------------------------- |
| $sum      | 计算总和。                                     | db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$sum : "$likes"}}}]) |
| $avg      | 计算平均值                                     | db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$avg : "$likes"}}}]) |
| $min      | 获取集合中所有文档对应值得最小值。             | db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$min : "$likes"}}}]) |
| $max      | 获取集合中所有文档对应值得最大值。             | db.mycol.aggregate([{$group : {_id : "$by_user", num_tutorial : {$max : "$likes"}}}]) |
| $push     | 在结果文档中插入值到一个数组中。               | db.mycol.aggregate([{$group : {_id : "$by_user", url : {$push: "$url"}}}]) |
| $addToSet | 在结果文档中插入值到一个数组中，但不创建副本。 | db.mycol.aggregate([{$group : {_id : "$by_user", url : {$addToSet : "$url"}}}]) |
| $first    | 根据资源文档的排序获取第一个文档数据。         | db.mycol.aggregate([{$group : {_id : "$by_user", first_url : {$first : "$url"}}}]) |
| $last     | 根据资源文档的排序获取最后一个文档数据         | db.mycol.aggregate([{$group : {_id : "$by_user", last_url : {$last : "$url"}}}]) |

## 管道的概念

管道在Unix和Linux中一般用于将当前命令的输出结果作为下一个命令的参数。

MongoDB的聚合管道将MongoDB文档在一个管道处理完毕后将结果传递给下一个管道处理。管道操作是可以重复的。

表达式：处理输入文档并输出。表达式是无状态的，只能用于计算当前聚合管道的文档，不能处理其它的文档。

这里我们介绍一下聚合框架中常用的几个操作：

- $project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。
- $match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。
- $limit：用来限制MongoDB聚合管道返回的文档数。
- $skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。
- $unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。
- $group：将集合中的文档分组，可用于统计结果。
- $sort：将输入文档排序后输出。
- $geoNear：输出接近某一地理位置的有序文档。

### 管道操作符实例

1、$project实例

```
db.article.aggregate(
    { $project : {
        title : 1 ,
        author : 1 ,
    }}
 );
```

2.$match实例

```
db.articles.aggregate( [
                        { $match : { score : { $gt : 70, $lte : 90 } } },
                        { $group: { _id: null, count: { $sum: 1 } } }
                       ] );
```

$match用于获取分数大于70小于或等于90记录，然后将符合条件的记录送到下一阶段$group管道操作符进行处理。

3.$skip实例

```
db.article.aggregate(
    { $skip : 5 });
```

经过$skip管道操作符处理后，前五个文档被"过滤"掉。



## Appinsight Server代码

https://www.cnblogs.com/xiaoyao-001/p/10043791.html



Server-BigData [logic-server] 

 * admin-monitor
 * api
 * appinsight
   * data-accessor[accessor]
   * data-accessor-common
   * data-accessor-app
   * data-accessor-h5
   * data-accessor-miniprogram
   * data-accessor-noncore

* common-all

  * ^ common-appinsight

  * ^ common-log 

* data-collector

* data-consumer

* interfaces

* gateway



### Server-BigData

```
{
  "artifactId": "logic-server",
  "parent": "spring-boot-starter-parent",
  "packaging": "pom",
  "modules": [
    "admin-monitor",
    "data-collector",
    "data-consumer",
    "interfaces",
    "api",
    "appinsight",
    "common-all"
  ]
}
```

#### admin-monitor

```
{
  "artifactId": "admin",
  "parent": "logic-server",
}
```

#### common-all

```
{
  "artifactId": "common-all",
  "parent": "logic-server",
  "packaging": "pom",
  "modules" : [
  	"common-appinsight",
  	"common-log"
  ]
}
```

##### common-log



common-appinsight





### accessor 

1. 各种数据库配置

   * clickhourse
   * mysql
   * mongo
   * regis

2. 开关配置

     enableAccessor



目前项目中用到的是 mongodb 和 clickhourse。clickhourse用来做数据分析，其他的存放在 mongodb。

目前mongodb有两个数据库



#### data-accessor-common

#### data-accessor-app

app 相关的数据处理

### api

业务层。提供接口供外界调用，外界通过接口获取各种数据

```
class AccountServiceImp implements IAccountService
```

application.yml

```
server:
  port: 8181
logging:
  prefix: web_api
spring:
  application:
    name: web-api
  cloud:
    zookeeper:
      connect-string: localhost:2181
    #      connect-string: 10.13.64.107:2181,10.13.83.20:2181,10.13.103.51:2181
    config:
      allow-override: true
  profiles:
    include: log
dubbo:
  registry:
    address: zookeeper://127.0.0.1:2181
#    address: zookeeper://10.13.64.107:2181,10.13.83.20:2181,10.13.103.51:2181
  consumer:
    check: 
```



### common-appinsight 

公共组件。通用的功能，如Base64、MD5, 各种枚举、Model定义。

如果存放到 mongoDB，对应的model以Doc结尾。

分析数据直接存入click-house。

### common-log

常用log格式、函数定义

### consumer

kakfa consumer。数据消费者，对上传的数据进行解析，写入数据库。

```
@SpringBootApplication
@EnableDubbo
ConsumerApplication

application.properties

spring.application.name=data-consumer
#log配置
logging.prefix = consumer
spring.profiles.include=appInsightCommon,log

#spring.kafka.bootstrap-servers=10.13.64.107:9092,10.13.83.20:9092,10.13.103.51:9092
spring.kafka.bootstrap-servers=127.0.0.1:9092
spring.kafka.consumer.group-id=sjtech-consumer-group-1
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.enable-auto-commit=true
#Kafka自定义配置
kafka.consumer.count=3

dubbo.registry.address=zookeeper://127.0.0.1:2181
```

Consumer.java

```
// 监听topic，如果有数据就会收到
@KafkaListener(topics = {APP_TOPIC, H5_TOPIC, MINI_PROGRAM_TOPIC})
public void consumeAppMessage(ConsumerRecord<String,String> record){
    try {
        switch (record.topic()){
            case APP_TOPIC:
                handleAppMessage(record.value());
                break;
            case H5_TOPIC:
                handleH5Message(record.value());
                break;
            case MINI_PROGRAM_TOPIC:
                handleMiniProgramMessage(record.value());
        }
    }catch (Exception e){
        LoggerFormat.error("kafka consumer parse message error");
        LoggerFormat.error(e);
    }
}
```



| 第三方  | 端口  | 路径           |
| ------- | ----- | -------------- |
| minio   | 4040  | 106.75.169.229 |
| mongodb | 27017 | 106.75.169.229 |
|         |       |                |

### gateway

API网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。API网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供REST/HTTP的访问API。

- Gateway这种，更像是业务网关，主要用来对应不同的客户端提供服务的，用于聚合业务的。各个微服务独立部署，职责单一，对外提供服务的时候需要有一个东西把业务聚合起来。
- Gateway这类网关可以实现熔断、重试等功能

### interfaces

面向接口编程，常用操作的接口声明



### 应用概览

```
AppOverviewController -> queryOverviewData

// private ISessionService mobileSessionService;
totalUserCount = mobileSessionService.userNumber(appIndex);
int[] sessionStatisticArray = mpSessionService.computeOverviewStatistic(appIndex, appVersion,
                    DateUtils.string2DateTime(from), DateUtils.string2DateTime(to));
// 
public class AppSessionServiceImp extends SessionServiceImp

@Override
public int[] computeOverviewStatistic(int appIndex, String appVersion, Date from, Date to) {
    int newUserCount = sessionDao.newUserCount(appIndex, appVersion, from, to);

    Map activeUserAndSessionCount = sessionDao.cptActiveUserCAndSessionC(appIndex, appVersion, from, to);
    int activeUserCount = ((BigInteger)activeUserAndSessionCount.get("activeUserCount")).intValue();
    int sessionCount = ((BigInteger)activeUserAndSessionCount.get("sessionCount")).intValue();

		// @Resource
    // private SessionDao sessionDao;
    int crashCount = sessionDao.computeSpecialFieldCount(appIndex, appVersion, from, to, "hasCrash");
    int anrCount = sessionDao.computeSpecialFieldCount(appIndex, appVersion, from, to, "hasAnr");
    return new int[]{newUserCount, activeUserCount, crashCount, anrCount, sessionCount};
}
```


```
// SessionMapper.xml
<select id="newUserCount" resultType="int">
    select
    uniqExact(innerUserIndex) as totalCount from session
    where <include refid="com.appinsight.ShareMapper.searchUnit"/>
    and isFirstSession = 1
</select>

<select id="cptActiveUserCAndSessionC" resultType="map">
    select uniqExact(innerUserIndex) as activeUserCount ,
    count(sessionId) as sessionCount from session
    where <include refid="com.appinsight.ShareMapper.searchUnit"/>
</select>
```



## 分析模型



* 留存分析

  留存分析是一种用来分析用户参与情况/活跃程度的分析模型，考察进行初始行为的用户中，有多少人会进行后续行为。这是用来衡量产品对用户价值高低的重要方法。用户生命周期

  * 初始行为
  * 后续行为

  * 时间顺序

  初始行为和后续行为一般是时间上递进的关系。第一周登录、第二周登录。升到80级、升到100级

* 行为事件分析

  行为事件其实就是用户在系统内进行的一些操作，比如登录、搜索、下单等。



* 漏斗分析

  漏斗分析是一套流程式数据分析，它能够科学反映用户行为状态以及从起点到终点各阶段用户转化率情况的重要分析模型。

  购买行为可以分很多步，登录、浏览、加购物车、结账等，



漏斗关键名称：

* 步骤  一般在时间线上是顺序发生的
* 事件 一般事件不同的
* 窗口期 漏斗分析必须指明窗口期，窗口期指的是第一步到最后一步的最大时间值。窗口期过大，结果很难归因。

* 分组 对结果使用特定的条件比如用户是男还是女进行进一步分组，漏斗的结果是用户，所以分组也是对用户进行分组。

  

### 项目中的分析

* FunnelDoc  漏斗模型
* FunnelStep 漏斗的步骤
* FunnelServiceImp 漏斗服务实现，增删改查

```
{
  "id": "5fe6fc66d90942688c0e23bf",
  "funnelName": "王雪峰的漏斗",
  "windowPeriod": 7,
  "steps": [
    {
      "name": "打开应用",
      "stepIdentify": "$ae_app_open",
      "filters": []
    },
    {
      "name": "分享",
      "stepIdentify": "contents_share",
      "filters": []
    },
    {
      "name": "登录",
      "stepIdentify": "login",
      "filters": []
    }
  ]
}
```



### 数据入库逻辑

DataCollectorController

```
@PostMapping("/{productType}/replay")
public HttpEntity<String> replayReceiver(@RequestParam("replay") MultipartFile multipartFile,
                                         @RequestParam("sessionId") String sessionId,
                                         @PathVariable("productType") String productType) {
    if (StringUtil.isBlank(sessionId)) return new ResponseEntity<>("empty session id", HttpStatus.BAD_REQUEST);
    try {
        byte[] req = multipartFile.getBytes();
        ObjectStorage.saveReplayObject(sessionId, req);
        return new ResponseEntity<>("success", HttpStatus.OK);
    } catch (Exception e) {
        LoggerFormat.error(e);
    }
    return new ResponseEntity<>(HttpStatus.INTERNAL_SERVER_ERROR);
}
```



```
ObjectStorage.saveReplayObject(sessionId, req);

public static void saveReplayObject(String sessionId, byte[] replayBytes) {
    ObjectStorage objectStorageManage = applicationContext.getBean(ObjectStorage.class);
    objectStorageManage.saveImp(sessionId,replayBytes);
}

@Async
public void saveImp(String sessionId, byte[] replayBytes){
    try {
        replayService.saveReplay(sessionId,replayBytes);
    } catch (Exception e) {
        LoggerFormat.error(e);
        LoggerFormat.info(String.format("save %s failed!",sessionId));
    }
}
```



```
// ReplayServiceImp.java

@Override
public void saveReplay(String sessionId, byte[] replayBytes) {
    try {
        myMinioClient.saveReplayObject(sessionId,new ByteArrayInputStream(replayBytes));
        sessionMongoRep.updateSessionReplayFlag(sessionId);
    } catch (Exception e) {
        LoggerFormat.error(e);
    }
}
```

```
// AppSessionMongoRep.java
/**
 * 设置会话回放标志位
 * @param sessionId 会话id
 */
@Async // 异步执行，调用者需要快速返回
public void updateSessionReplayFlag(String sessionId) {
    Query query = Query.query(Criteria.where("sessionId").is(sessionId));
    SessionDoc sessionDoc = mongoTemplate.findAndModify(query, Update.update("hasReplay", true),
            SessionDoc.class, SESSION_COLLECTION_NAME);
    if (sessionDoc == null) {
        sessionReplayFlagsCache.add(sessionId);
        if(LoggerFormat.isDebugEnable()) {
            LoggerFormat.debug("cache session replay flag for session:" + sessionId);
        }
    }else {
        sessionDoc.setHasReplay(true);
        // 重新入库一份clickhouse数据
        appWaitingArea.entry(Session.copyFromSessionDoc(sessionDoc));
        // 开始做截屏逻辑
        screenShotTask.takeScreenShot(sessionDoc, null);
    }
}
```



```
AppWaitingArea
```